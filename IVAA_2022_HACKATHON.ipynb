{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMHG/fjptLJgE9/bUVebPfu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Practice Hackathon"],"metadata":{"id":"B_kyb-DBY_LJ"}},{"cell_type":"code","source":["#Libraries\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","from sklearn import datasets as dat\n","from sklearn import tree\n","from sklearn import metrics as met\n","from sklearn import model_selection as mod\n","from sklearn import linear_model as lin\n","from sklearn import preprocessing as pre\n","from sklearn import pipeline as pip # sklearn pipeline\n","from sklearn import svm\n","from sklearn import impute as imp\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn import compose as com\n","from sklearn import ensemble as ens\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"Xlv66YG_ZH83"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Data read from file\n","\n","df_data = pd.read_csv(\"/content/final_data_ivaa.csv\",sep=\",\")\n","df_data.head(3)"],"metadata":{"id":"X8ez_K7vZfEV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_data.info()"],"metadata":{"id":"1yQucYwTZf0j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Data columns drop\n","\n","df_data = df_data.drop(columns=['Kategorı','Register_date'])"],"metadata":{"id":"9IYFPW9GZfs1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Identify the unique values\n","\n","pd.set_option('display.max_rows', None)\n","dict = {}\n","\n","for i in list(df_data.columns):\n","  dict[i] = df_data[i].value_counts().shape[0]\n","\n","uniq = pd.DataFrame(dict, index = [\"Unique counts\"]).transpose()\n","uniq.sort_values(by=\"Unique counts\")"],"metadata":{"id":"wjeqcBHNZfp5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Unique values\n","\n","data[\"Colum_Name\"].unique()"],"metadata":{"id":"kuP_TcxDZfms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(df_data.columns)):\n","  df_data[df_data.columns[i]].fillna(0, inplace=True)"],"metadata":{"id":"v9OUhJLbZpDj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Finding Data has null value or not\n","\n","df_data.isnull().sum()"],"metadata":{"id":"bVh6FkKoZpAV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Split data to train and test\n","\n","X_train, X_test, y_train, y_test = mod.train_test_split(\n","    df_data.drop(\"CASE_DURUM\", axis=1), df_data[\"CASE_DURUM\"], test_size=0.33, random_state=42)"],"metadata":{"id":"EzwfH4rfZo9S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#categorical colums\n","\n","cat_columns = list(X_train.select_dtypes(include=\"object\").columns)\n","cat_columns"],"metadata":{"id":"oeITKQUPZxom"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#numerical colums\n","num_columns = list(X_train.select_dtypes(exclude=\"object\").columns)\n","num_columns"],"metadata":{"id":"YPn5DVY5ZxlR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Categoricial colums distribution\n","\n","for col in cat_columns:\n","  if len(X_train[col].unique()) < 200:\n","    X_train[col].value_counts().plot(kind=\"bar\", figsize=(10, 6))\n","    plt.title(col)\n","    plt.show()"],"metadata":{"id":"QReVrCOFZxiA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Numericial colums distribution\n","\n","for col in num_columns:\n","  sns.distplot(X_train[col])\n","  plt.show()"],"metadata":{"id":"H-60xKMsZ3kM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pipeline with İmputer and Column Transformasyon\n","\n","#ct_num = com.ColumnTransformer([\n","#    (\"num_skewed\", pre.FunctionTransformer(np.log1p), num_columns)\n","#])\n","\n","pipe_num = pip.Pipeline([\n","    (\"scaler\", pre.StandardScaler()),\n","    (\"imp\", imp.SimpleImputer(strategy=\"mean\"))\n","])\n","\n","pipe_cat = pip.Pipeline([\n","    (\"imp\", imp.SimpleImputer(strategy=\"most_frequent\")),\n","    (\"encoding\", pre.OneHotEncoder(handle_unknown=\"ignore\", sparse=True)) \n","])\n","\n","ct = com.ColumnTransformer([\n","    (\"num\", pipe_num, num_columns),\n","    (\"cat\", pipe_cat, cat_columns)\n","])\n","\n","ct.fit_transform(X_train)"],"metadata":{"id":"Z7LRIQePZ3hI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SGDClassifier\n","pipe_all = pip.Pipeline([\n","    (\"ct\", ct),\n","    (\"sgd\", lin.SGDClassifier(random_state=42))\n","])\n","\n","pipe_all.fit(X_train, y_train)"],"metadata":{"id":"fvJ6leFKZ3eC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LogisticRegression\n","\n","pipe_LG = pip.Pipeline([\n","    (\"ct\", ct),\n","    (\"log_reg\", lin.LogisticRegression(random_state=42))\n","])\n","\n","pipe_LG.fit(X_train, y_train)"],"metadata":{"id":"y5UWtXtLamzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mod.cross_val_score(pipe_LG, X_train, y_train, cv=3, scoring=\"accuracy\").mean()\n","pipe_LG.fit(X_train, y_train)\n","y_pred = pipe_LG.predict(X_test)\n","print(met.classification_report(y_test, y_pred))"],"metadata":{"id":"oxzexJXKav8e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Decision Tree\n","\n","pipe_DT = pip.Pipeline([\n","    (\"ct\", ct),\n","    (\"DT\", tree.DecisionTreeClassifier(max_depth=6, min_samples_split=5,random_state=42))\n","])\n","\n","pipe_DT.fit(X_train, y_train)\n","y_pred = pipe_DT.predict(X_test)\n","met.accuracy_score(y_test, y_pred)\n","\n","mod.cross_val_score(pipe_DT, X_train, y_train, cv=5, scoring=\"accuracy\").mean()\n"],"metadata":{"id":"HQ2RHVlabKFu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Learning Curve\n","\n","def plotLearningCurve(est, X_train, y_train, X_test, y_test, n_iter=10, minY=0, maxY=1, useF1Score=False):\n","  x_values = []\n","  y_values_train = []\n","  y_values_test = []\n","\n","  for i in np.linspace(100, len(X_train), n_iter):\n","    i = int(i)\n","\n","    # select a subset of training data\n","    X_train_temp = X_train[:i]\n","    y_train_temp = y_train[:i]\n","\n","    # create the model\n","    est.fit(X_train_temp, y_train_temp)\n","\n","    # evaluate train set\n","    y_pred_train = est.predict(X_train_temp)\n","    if useF1Score:\n","      train_score = met.f1_score(y_train_temp, y_pred_train)\n","    else:\n","      train_score = met.accuracy_score(y_train_temp, y_pred_train)\n","\n","    # evaluate test set\n","    y_pred_test = est.predict(X_test)\n","    if useF1Score:\n","      test_score = met.f1_score(y_test, y_pred_test)\n","    else:\n","      test_score = met.accuracy_score(y_test, y_pred_test)\n","\n","    # populate lists\n","    y_values_train.append(train_score)\n","    y_values_test.append(test_score)\n","    x_values.append(i)\n","  \n","  myLabel = \"Accuracy\"\n","  if useF1Score:\n","    myLabel = \"F1-Score\"\n","  plt.figure(figsize=(10, 6))\n","  plt.plot(x_values, y_values_train, label=\"train\")\n","  plt.plot(x_values, y_values_test, label=\"test\")\n","  plt.legend()\n","  plt.ylabel(myLabel)\n","  plt.xlabel(\"# of training samples\")\n","  plt.grid(True)\n","  plt.ylim(minY, maxY)\n","  plt.show()"],"metadata":{"id":"pV4Sx2aKb9Jw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plotLearningCurve(pipe_DT,\n","                  X_train, y_train, X_test, y_test, \n","                  n_iter=10, minY=0.6, maxY=0.72, useF1Score=False)"],"metadata":{"id":"48Tc0tEqcG2r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 0\n","list_of_Class = [\"SGDClassifier\",\"DecisionTreeClassifier\",\"LogisticRegression\"]\n","for est in [pipe_all, \n","            pipe_DT,\n","            pipe_LG]: \n","\n","  pipe = pip.Pipeline([\n","        (\"est\", est)\n","  ])\n","\n","  if hasattr(est, \"predict_proba\"):\n","    myMethod = \"predict_proba\"\n","  else:\n","    myMethod = \"decision_function\"\n","\n","  y_scores = mod.cross_val_predict(pipe, X_train, y_train,\n","                                   cv=5, method=myMethod)\n","  if myMethod == \"predict_proba\":\n","    y_scores = y_scores[:, 1] # probabilities for True class\n","\n","  fpr, tpr, thresholds = met.roc_curve(y_train, y_scores)\n","  auc_score = met.roc_auc_score(y_train, y_scores)\n","\n","  print(list_of_Class[i] + \":\", auc_score)\n","\n","  plt.plot(fpr, tpr, label=list_of_Class[i])\n","  i = i + 1\n","\n","plt.title(\"ROC Curve\")\n","plt.xlabel(\"fpr\")\n","plt.ylabel(\"tpr\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"hoOKJg1dcHia"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Machine Learning By IA"],"metadata":{"id":"hia5q_v63UJ6"}},{"cell_type":"markdown","source":["Some supervised learning methods: Linear Regression, Logistic Regression ,Decision Tree, Random Forests, SVMs (Support Vector Machines), ANNs (Artificial Neural Networks)\n"],"metadata":{"id":"a2et12Ni4RQx"}},{"cell_type":"markdown","source":["Some unsupervised learning methods: Clustering → KMeans, Agglomerative Clustering, DBSCAN, etc.\n","\n","Dimensionality Reduction → Principal Component Analysis (PCA), t-Distributed Stochastic Neighbor Embedding (t-SNE)\n","\n","Association Rule Mining → Apriori algorithm\n","\n","Anomaly Detection → One-class SVM "],"metadata":{"id":"yrHi3P6jNJZy"}},{"cell_type":"markdown","source":["Overfitting: 1. increase the amount of training data 2. Reduce the number of features 3. Regularization"],"metadata":{"id":"Xeh8mvIKW9po"}},{"cell_type":"markdown","source":["Underfitting: 1. Try to use a more complex algorithm with more parameter 2. Increase the number of features 3. Reduce regularization\n"],"metadata":{"id":"nxbNSKR_XCSa"}},{"cell_type":"markdown","source":["Note: Before start to split your data, ALWAYS do shuffing."],"metadata":{"id":"YDSYStuvXGZe"}},{"cell_type":"markdown","source":["## Data PreProcessing"],"metadata":{"id":"6OqVsHk5XWzq"}},{"cell_type":"code","source":["#reading data from file\n","housing = pd.read_csv(\"/content/housing.csv\")\n","housing.head()"],"metadata":{"id":"2XRn4t18XzT5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#data frame shape\n","housing.shape"],"metadata":{"id":"z8NXaijoXiaD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["housing.isnull().sum()"],"metadata":{"id":"4k6wb3G6X4Tv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["housing.dtypes"],"metadata":{"id":"6JYp1J_8YJ4I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Below shows the unique labels\n","housing[\"ocean_proximity\"].unique()"],"metadata":{"id":"_4wlV8FwYNU3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#target y distribution on boxpot\n","sns.boxplot(y)"],"metadata":{"id":"_fMCQmKOXiWx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#target y distribution on distplot\n","sns.distplot(y)"],"metadata":{"id":"Uqit-wWJXf9n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#target y distribution on train data\n","y_train.value_counts().plot(kind=\"bar\")"],"metadata":{"id":"axzNP18abW0O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Linear Regression"],"metadata":{"id":"D83ERBt2P630"}},{"cell_type":"markdown","source":["**Simple linear regression :** a single independent variable is used to predict the value of a dependent variable.\n","Equation : y=A+BX\n"],"metadata":{"id":"-1q0CYY0WvJu"}},{"cell_type":"markdown","source":["**Multiple linear regression :** two or more independent variables are used to predict the value of a dependent variable. The difference between the two is the number of independent variables. Equation : y=A+BX1+CX2+DX3"],"metadata":{"id":"zTa0FO_1W2ug"}},{"cell_type":"markdown","source":["We need to find θ which minimizes the cost function (RMSE or MSE). So Using Normal Equation (Scikit-Linear Regression - No Scalling) and Using Gradient Descent (Scikit-SGDRegressor - Scalling)\n"],"metadata":{"id":"xlqNm8jEYAi4"}},{"cell_type":"markdown","source":["**Gradient Descent:** With this algorithm, we must use StandardScaler\n","\n","*  **Batch Gradient Descent :** “Eta” is the “learning rate” here. It involves calculations over the full training set X, at each Gradient Descent step! As a result it is terribly slow on very large training sets. To find a good learning rate, you can use grid search.\n","*  **Stochastic Gradient Descent :** Stochastic Gradient Descent just picks a random instance in the training set at every step and computes the gradients based only on that single instance. So this makes the algorithm much faster since it has very little data to manipulate at every iteration.\n","\n","*  **Mini-batch Gradient Descent :** Mini-batch GD computes the gradients on small random sets of instances called mini- batches."],"metadata":{"id":"_9utwj7uZfl-"}},{"cell_type":"markdown","source":["**Polynomial Regression:** Data is actually more complex. In order to see your assumtion is not overfittin or underfitting, we must check with 1. Cross-Validation 2. Learning Curves\n"],"metadata":{"id":"rK1j5fiLe0F9"}},{"cell_type":"markdown","source":["### Linear Regression Algorithms"],"metadata":{"id":"jvPSKimCyGAN"}},{"cell_type":"markdown","source":["####Library Package"],"metadata":{"id":"cHp-mVoiS8gO"}},{"cell_type":"code","source":["#Adding Library Packages\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","#from sklearn.linear_model import LinearRegression\n","from sklearn import linear_model as lin\n","from sklearn import preprocessing as pre\n","from sklearn import metrics as met\n","from sklearn import model_selection as mod\n","from sklearn import pipeline as pip"],"metadata":{"id":"h31vuvKHTCQi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Distrubution of Y data"],"metadata":{"id":"MlY5Jl3D0T-v"}},{"cell_type":"code","source":["#target y distribution on distplot\n","sns.distplot(y)"],"metadata":{"id":"iA9niKOm0Ylf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#target y distribution on boxpot\n","sns.boxplot(y)"],"metadata":{"id":"l9e76usE0pBq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Batch Gradient Descent"],"metadata":{"id":"xVYfwYZ8jpRf"}},{"cell_type":"code","source":["m = 200\n","np.random.seed(42)\n","X = np.random.rand(m, 1) * 6 - 3 # [-3, 3)\n","y = 3 * X + 4 + 3*np.random.rand(m, 1)\n","\n","ones_vect = np.ones((m, 1))\n","X_2 = np.concatenate((ones_vect, X), axis=1)\n","\n","for eta in [0.001, 0.1, 10]:\n","  # randomly initialize theta values\n","  theta = np.random.rand(2, 1)\n","\n","  #eta = 0.1\n","  n_steps = 15\n","\n","  for i in range(n_steps):\n","    # compute the gradient\n","    gradient = (2/m) * X_2.T.dot(X_2.dot(theta) - y)\n","    # update theta values\n","    theta = theta - eta*gradient\n","\n","    # make prediction with current theta values\n","    y_pred = X_2.dot(theta)\n","    \n","    if i == 0:\n","      myColor = \"green\"\n","    elif i == n_steps - 1:\n","      myColor = \"red\"\n","    else:\n","      myColor = \"orange\"\n","    plt.scatter(X, y_pred, color=myColor)\n","\n","  plt.scatter(X, y, color=\"blue\")\n","  plt.title(\"Eta:\" + str(eta))\n","  plt.show()"],"metadata":{"id":"r8daXLDkj_zn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Stochastic Gradient Descent (SGD)"],"metadata":{"id":"EauV7wHprLHy"}},{"cell_type":"code","source":["#data is split to train and test data\n","X_train, X_test, y_train, y_test = mod.train_test_split(X, y, test_size=0.25, random_state=42)"],"metadata":{"id":"xN6yMex1rN5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#pipeline \n","pipe = pip.Pipeline([\n","        (\"scaler\", pre.StandardScaler()),              #Scaling\n","        (\"sgd\", lin.SGDRegressor(random_state=42))     #Model_Learning_Method\n","])\n","\n","pipe.fit(X_train, y_train.ravel())                     #Model_Learning_Fitted\n","\n","y_pred = pipe.predict(X_test)                          #Prediction\n","\n","met.mean_squared_error(y_test, y_pred, squared=False)  #RMSE score\n","\n","mod.cross_val_score(pipe, X_train, y_train.ravel(), cv=3, scoring=\"neg_root_mean_squared_error\").mean() * -1   #Cross Validation Score"],"metadata":{"id":"6xB1cD8Mss8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GridSearchCV\n","myParams = {\n","    \"sgd__alpha\": [0.001, 0.01, 0.1],\n","    \"sgd__penalty\": [\"l1\", \"l2\"],\n","    \"sgd__eta0\": [0.01, 0.1, 1],\n","    \"sgd__max_iter\": [10000, 50000]\n","}\n","\n","grid = mod.GridSearchCV(pipe, myParams, scoring=\"neg_root_mean_squared_error\", cv=3)\n","grid.fit(X_train, y_train.ravel())\n","grid.best_params_     #Best parameters"],"metadata":{"id":"xaMllWNHuQQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["grid.best_score_      #Best scores"],"metadata":{"id":"ZojURRq_ucaT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prediction for best parameters\n","y_pred = grid.best_estimator_.predict(X_test)\n","met.mean_squared_error(y_test, y_pred, squared=False)"],"metadata":{"id":"gIIOiGmputil"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Polynomial Data"],"metadata":{"id":"Ie_iAYL5vi7l"}},{"cell_type":"code","source":["#data\n","m = 500\n","X = np.random.rand(m, 1) * 6 - 3\n","y = 3 * X**2 + 4 * X + 5 + 4*np.random.rand(m, 1)"],"metadata":{"id":"pARsv372vmKK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#data is split to train and test data\n","X_train, X_test, y_train, y_test = mod.train_test_split(X, y, test_size=0.25, random_state=42)"],"metadata":{"id":"Z6e8QpJ1v03h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe = pip.Pipeline([\n","      (\"poly\", pre.PolynomialFeatures(degree=2)),    #polinomal regulazation\n","      (\"scaler\", pre.StandardScaler()),              #Scaling\n","      (\"sgd\", lin.SGDRegressor(random_state=42))     #Model_Learning_Method\n","])\n","\n","pipe.fit(X_train, y_train.ravel())\n","\n","y_pred = pipe.predict(X_test)\n","\n","plt.scatter(X_train, y_train)\n","plt.scatter(X_test, y_pred)\n","plt.show()"],"metadata":{"id":"Do0RsHbMvxTX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Learning Curves"],"metadata":{"id":"FGkG4FeLwq2r"}},{"cell_type":"code","source":["np.linspace(10, len(X_train), 10)"],"metadata":{"id":"HlWvWEIbwtyP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plotLearningCurve(est, X_train, y_train, X_test, y_test, n_iter=10, minY=0, maxY=1):\n","  x_values = []\n","  y_values_train = []\n","  y_values_test = []\n","\n","  for i in np.linspace(10, len(X_train), n_iter):\n","    i = int(i)\n","\n","    # select a subset of training data\n","    X_train_temp = X_train[:i]\n","    y_train_temp = y_train[:i]\n","\n","    # create the model\n","    est.fit(X_train_temp, y_train_temp)\n","\n","    # evaluate train set\n","    y_pred_train = est.predict(X_train_temp)\n","    train_score = met.mean_squared_error(y_train_temp, y_pred_train, squared=False)\n","\n","    # evaluate test set\n","    y_pred_test = est.predict(X_test)\n","    test_score = met.mean_squared_error(y_test, y_pred_test, squared=False)\n","\n","    # populate lists\n","    y_values_train.append(train_score)\n","    y_values_test.append(test_score)\n","    x_values.append(i)\n","  \n","  plt.figure(figsize=(10, 6))\n","  plt.plot(x_values, y_values_train, label=\"train\")\n","  plt.plot(x_values, y_values_test, label=\"test\")\n","  plt.legend()\n","  plt.ylabel(\"RMSE\")\n","  plt.xlabel(\"# of training samples\")\n","  plt.grid(True)\n","  plt.ylim(minY, maxY)\n","  plt.show()"],"metadata":{"id":"Ov9D0ff_xXD4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#learning Curve for seeing overfitting and underfitting conditions\n","plotLearningCurve(pipe, X_train, y_train.ravel(), X_test, y_test.ravel(), n_iter=10, minY=0, maxY=10)"],"metadata":{"id":"83v2-swXxfcf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Logistic Regression"],"metadata":{"id":"rkEF03ML91bf"}},{"cell_type":"markdown","source":["**Sigmoid Function:** it (referred with 𝝈) is a S shaped function, which always output a numeric value between 0 and 1."],"metadata":{"id":"JnZn4yGV96xu"}},{"cell_type":"markdown","source":["**Log Loss:** The cost function. For the cost function, cross entropy is used during the training.\n"],"metadata":{"id":"DsqNqmoXAHJu"}},{"cell_type":"markdown","source":["**The hyperparameter:** It is C. The higher the value of C, the less the model is regularized."],"metadata":{"id":"0HYllVBsAQ-Q"}},{"cell_type":"markdown","source":["**Multiclass Classification :**\n","\n","*   Binary classification → 2 classes\n","*   Multiclass classification → Strictly more than 2 classes"],"metadata":{"id":"46IkW9voA8nB"}},{"cell_type":"markdown","source":["**Note :** First, the model calculates the logit scores for each class. Than it uses softmax function to calculate probability of each class."],"metadata":{"id":"_a7i-oNEBoBk"}},{"cell_type":"markdown","source":["In LogisticRegression function, we need to set multi_class hyperparameter to \"multinomial\" to switch it to Softmax Regression. Additionally, solver parameter should be \"lbfgs\"."],"metadata":{"id":"Z2NjXwfjCfD4"}},{"cell_type":"markdown","source":["### Logistic Regression Algorithms"],"metadata":{"id":"yIXn5HkvCw50"}},{"cell_type":"markdown","source":["####Library Package"],"metadata":{"id":"MJk3a7HmC1SX"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","\n","from sklearn import datasets as dat\n","from sklearn import model_selection as mod\n","from sklearn import preprocessing as pre\n","from sklearn import pipeline as pip\n","from sklearn import linear_model as lin\n","from sklearn import metrics as met"],"metadata":{"id":"q2w-xpkMDPTA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Single Classification Model"],"metadata":{"id":"aR0lyF-VEC6-"}},{"cell_type":"code","source":["#Iris data load\n","data_obj = dat.load_iris()\n","X = data_obj.data\n","y = data_obj.target"],"metadata":{"id":"iZCPnR5dE0wW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_binary = (y==2)"],"metadata":{"id":"wFJXzCDXERpQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = mod.train_test_split(\n","    X, y_binary, test_size=0.33, random_state=42)"],"metadata":{"id":"BcPnbFe-EOXM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"id":"MPv54bynEklH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test.shape"],"metadata":{"id":"MPUT0iH8Elcp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe = pip.Pipeline([\n","        (\"scaler\", pre.StandardScaler()),\n","        (\"log_reg\", lin.LogisticRegression(random_state=42))\n","])\n","\n","y_pred = mod.cross_val_predict(pipe, X_train, y_train, cv=3, method=\"predict\")"],"metadata":{"id":"EUCl5vZ7Eu5q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"emvl9wK0IOwI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#predict the target propability for each label\n","mod.cross_val_predict(pipe, X_train, y_train, cv=3, method=\"predict_proba\")\n","np.set_printoptions(suppress=True)\n","y_proba = pipe.predict_proba(X_test)"],"metadata":{"id":"NmgC9M89I_5m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mat = met.confusion_matrix(y_train, y_pred)\n","mat"],"metadata":{"id":"Bp4T4GqaJRur"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.heatmap(mat, annot=True, cmap=\"RdBu_r\")"],"metadata":{"id":"hRnb_zLmMGGe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(met.classification_report(y_train, y_pred))"],"metadata":{"id":"tLC4qRM0MNrk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Multiclass Classification Model"],"metadata":{"id":"AZrppqTxMiZA"}},{"cell_type":"code","source":["pipe = pip.Pipeline([\n","        (\"scaler\", pre.StandardScaler()),\n","        (\"log_reg\", lin.LogisticRegression(multi_class=\"multinomial\",\n","                                           solver=\"lbfgs\",\n","                                           random_state=42))\n","])\n","\n","params = {\n","    \"log_reg__penalty\": [\"l2\", \"none\"],\n","    \"log_reg__C\": [0.1, 1, 10]\n","}"],"metadata":{"id":"jvA1X3rDMl9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["grid = mod.GridSearchCV(pipe, params, scoring=\"accuracy\", cv=3)\n","grid.fit(X_train, y_train)"],"metadata":{"id":"PbFIqs66OZed"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["grid.best_params_"],"metadata":{"id":"QIEaOZe9ObiP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["grid.best_score_"],"metadata":{"id":"j4aXWuK0Obe_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = grid.best_estimator_.predict(X_test)\n","met.accuracy_score(y_test, y_pred)"],"metadata":{"id":"RsiauJ2GOhf5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Decision Trees"],"metadata":{"id":"08j6NtsnPSp7"}},{"cell_type":"markdown","source":["*   Decision Trees are both used for **Regression** and **Classification** tasks.\n","*   Decision Trees do not require scaling.\n","*   A control parameter is **max_depth**.\n","*   **Gini** attribute continoues until all the sample in the node belongs to same class where **Gini = 0**.\n","*   **min_samples_split:** the minimum number of samples a node must have before it can be split.\n","*   **min_samples_leaf:** the minimum number of samples a leaf node must have.\n","\n","\n","\n"],"metadata":{"id":"ER0G6j2pPelE"}},{"cell_type":"markdown","source":["###Decision Trees Algorithms "],"metadata":{"id":"Mi4N1SRoT-9x"}},{"cell_type":"markdown","source":["####Library Package"],"metadata":{"id":"gx3ntwHjUQUj"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","\n","from sklearn import datasets as dat\n","from sklearn import model_selection as mod\n","from sklearn import preprocessing as pre\n","from sklearn import pipeline as pip\n","from sklearn import linear_model as lin\n","from sklearn import metrics as met\n","from sklearn import tree\n","\n","from sklearn import ensemble as ens"],"metadata":{"id":"TX4HBuY7UE2r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Algorithms"],"metadata":{"id":"9n5IB-i3UZ7T"}},{"cell_type":"code","source":["data_obj = dat.load_iris()\n","X = data_obj.data\n","y = data_obj.target"],"metadata":{"id":"QIflsCOuUeIt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = mod.train_test_split(\n","    X, y, test_size=0.33, random_state=42)"],"metadata":{"id":"Xu2EyFScUj9H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dct_tree = tree.DecisionTreeClassifier(max_depth=2, random_state=42)\n","dct_tree.fit(X_train, y_train)"],"metadata":{"id":"Lg1fuPezUoB_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tree.export_graphviz(\n","        dct_tree,\n","        out_file=\"iris_tree.dot\",\n","        feature_names=data_obj.feature_names,\n","        class_names=data_obj.target_names,\n","        rounded=True,\n","        filled=True\n","    )"],"metadata":{"id":"JQ8sbuVmUrDh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! dot -Tpng iris_tree.dot -o iris_tree.png"],"metadata":{"id":"qGAwH8ltUtXd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train_binary = (y_train == 2)\n","y_test_binary = (y_test == 2)"],"metadata":{"id":"r22kvEXfqqZY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.Series(y_train).value_counts()"],"metadata":{"id":"VH8dQLaPtR_b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.Series(y_train).value_counts().plot(kind=\"bar\")"],"metadata":{"id":"D8WK5-p3ssOU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.Series(y_train_binary).value_counts().max() / len(y_train_binary)"],"metadata":{"id":"Nj_nykKItElD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dct_tree = tree.DecisionTreeClassifier(random_state=42)\n","\n","params = {\n","    \"max_depth\": [4, 5, 6],\n","    \"min_samples_split\": [2, 5, 10]\n","}\n","\n","grid = mod.GridSearchCV(dct_tree, params, cv=3, scoring=\"accuracy\")\n","grid.fit(X_train, y_train_binary)"],"metadata":{"id":"C7HKbmznUyfT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["grid.best_params_"],"metadata":{"id":"zPNE1dZjU1kL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["grid.best_score_"],"metadata":{"id":"hsM2jSfUU2_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = grid.best_estimator_.predict(X_test)\n","y_pred[:5]"],"metadata":{"id":"jmoF_jAWU28F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_proba = grid.best_estimator_.predict_proba(X_test)\n","y_proba[:5]"],"metadata":{"id":"EHTpk2hcVBRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["precision, recall, thresholds = met.precision_recall_curve(y_test_binary, y_pred)"],"metadata":{"id":"pnsjFwSeoEx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"precision\", len(precision))\n","print(\"recall\", len(recall))\n","print(\"thresholds\", len(thresholds))"],"metadata":{"id":"g40v2jD9siP6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["met.roc_auc_score(y_test_binary, y_pred)"],"metadata":{"id":"H-p8s4qWuRLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for est in [tree.DecisionTreeClassifier(random_state=42), \n","            lin.SGDClassifier(random_state=42),\n","            ens.RandomForestClassifier(random_state=42)]:\n","  pipe = pip.Pipeline([\n","        (\"scaler\", pre.StandardScaler()),\n","        (\"est\", est)\n","  ])\n","\n","  if hasattr(est, \"predict_proba\"):\n","    myMethod = \"predict_proba\"\n","  else:\n","    myMethod = \"decision_function\"\n","\n","  y_scores = mod.cross_val_predict(pipe, X_train, y_train_binary,\n","                                   cv=5, method=myMethod)\n","  if myMethod == \"predict_proba\":\n","    y_scores = y_scores[:, 1] # probabilities for True class\n","  \n","  fpr, tpr, thresholds = met.roc_curve(y_train_binary, y_scores)\n","  auc_score = met.roc_auc_score(y_train_binary, y_scores)\n","  print(est.__class__.__name__, auc_score)\n","\n","  plt.plot(fpr, tpr, label=est.__class__.__name__)\n","\n","plt.title(\"ROC Curve\")\n","plt.xlabel(\"fpr\")\n","plt.ylabel(\"tpr\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"nxUYhy_QvQLX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Imbalanced Learning"],"metadata":{"id":"6aGuAPrWd15Y"}},{"cell_type":"markdown","source":["*  One common approach for the imbalanced learning is resampling.\n","*  **Undersampling :** Removes random records from majority class\n","    - RandomUnderSampler\n","    - TomekLinks\n","*  **Oversampling :** Duplicates random records from minority class\n","    - RandomOverSampler\n","    - SMOTE\n","\n","\n","\n","\n"],"metadata":{"id":"Wcy8lsQEeAR_"}},{"cell_type":"markdown","source":["### Library Package"],"metadata":{"id":"_LcQhwkHgirp"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","from sklearn import datasets as dat\n","from sklearn import tree\n","from sklearn import metrics as met\n","from sklearn import model_selection as mod\n","from sklearn import linear_model as lin\n","from sklearn import preprocessing as pre\n","from sklearn import pipeline as pip # sklearn pipeline\n","from imblearn import pipeline as imbPip # imblearn pipeline\n","from imblearn import under_sampling as und\n","from imblearn import over_sampling as ove"],"metadata":{"id":"dYM7IN_vgozI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Algorithms"],"metadata":{"id":"sJIMm-LShmtA"}},{"cell_type":"code","source":["rus = und.RandomUnderSampler(sampling_strategy=0.2, random_state=42)\n","X_res, y_res = rus.fit_resample(X, y)"],"metadata":{"id":"gC5ZibvfiLEy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.Series(y).value_counts()"],"metadata":{"id":"T9Hmzyr1iWTd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.Series(y_res).value_counts()"],"metadata":{"id":"0CCvmeRGiMW7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe = imbPip.Pipeline([\n","      (\"resample\", ove.RandomOverSampler(sampling_strategy=0.3, random_state=42)),\n","      (\"scaler\", pre.StandardScaler()),\n","      (\"sgd\", lin.SGDClassifier(random_state=42))\n","])\n","\n","mod.cross_val_score(pipe, X, y, cv=3, scoring=\"f1\").mean()"],"metadata":{"id":"7nd-x-Eiigjm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tl = und.TomekLinks(sampling_strategy=\"all\")\n","X_res, y_res = tl.fit_resample(X, y)\n","\n","pd.Series(y_res).value_counts()"],"metadata":{"id":"lXCCVgrsioFk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe = imbPip.Pipeline([\n","      (\"resample\", ove.SMOTE(sampling_strategy=0.3, k_neighbors=5, random_state=42)),\n","      (\"scaler\", pre.StandardScaler()),\n","      (\"sgd\", lin.SGDClassifier(random_state=42))\n","])\n","\n","mod.cross_val_score(pipe, X, y, cv=3, scoring=\"f1\").mean()"],"metadata":{"id":"s5RE9szMiosl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sampling techniques\n","for sampler in [und.RandomUnderSampler(random_state=42),\n","                ove.RandomOverSampler(random_state=42),\n","                ove.SMOTE(random_state=42)]:\n","  pipe_sampler_sgd = imbPip.Pipeline([\n","        (\"resample\", sampler),\n","        (\"scaler\", pre.StandardScaler()),\n","        (\"sgd\", lin.SGDClassifier(random_state=42))\n","  ])\n","\n","  params = {\n","      \"resample__sampling_strategy\": [0.35, 0.4],\n","      \"sgd__alpha\": [0.001, 0.005],\n","      \"sgd__max_iter\": [500, 1000, 2000]\n","  }\n","\n","  grid_sampler_sgd = mod.GridSearchCV(pipe_sampler_sgd, params, cv=3, scoring=\"roc_auc\")\n","  grid_sampler_sgd.fit(X_train, y_train)\n","\n","  print(\"GridSearchCV:\", sampler.__class__.__name__, grid_sampler_sgd.best_score_)\n","\n","  y_scores = grid_sampler_sgd.best_estimator_.decision_function(X_test)\n","  fpr, tpr, thresholds = met.roc_curve(y_test, y_scores)\n","  plt.plot(fpr, tpr, label=sampler.__class__.__name__)\n","\n","# class weight tech\n","pipe_classw_sgd = pip.Pipeline([\n","      (\"scaler\", pre.StandardScaler()),\n","      (\"sgd\", lin.SGDClassifier(random_state=42))\n","])\n","\n","params = {\n","    \"sgd__alpha\": [0.001, 0.005],\n","    \"sgd__max_iter\": [500, 1000, 2000],\n","    \"sgd__class_weight\": [\"balanced\", {0:1, 1:2}, {0:1, 1:3}]\n","}\n","\n","grid_classw_sgd = mod.GridSearchCV(pipe_classw_sgd, params, cv=3, scoring=\"roc_auc\")\n","grid_classw_sgd.fit(X_train, y_train)\n","print(\"GridSearch Class Weight:\", grid_classw_sgd.best_score_)\n","\n","y_scores = grid_classw_sgd.best_estimator_.decision_function(X_test)\n","fpr, tpr, thresholds = met.roc_curve(y_test, y_scores)\n","plt.plot(fpr, tpr, label=\"class_weight\")\n","\n","plt.plot([0, 1], [0, 1], \"r--\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"2oslIXQ8hurA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SVM Classification"],"metadata":{"id":"Dr8S-T-zmZo3"}},{"cell_type":"markdown","source":["*   Scale your data before using SVMs.\n","\n","*   Nonlinear SVM Classification, some problems are not linearly separable so one approach might be adding Polynomial Features, and this operation can make the dataset linearly separable.\n","   - Another technique to tackle nonlinear problems is to add features computed using a similarity function that measures how much each instance resembles a particular landmark.\n","\n","\n","\n","\n"],"metadata":{"id":"5w_PXuGamdKu"}},{"cell_type":"markdown","source":["**Note :** Gaussian RBF kernel, If your model is overfitting, you should reduce gamma, and if it is underfitting, you should increase it (similar to the C hyperparameter)."],"metadata":{"id":"m8BNNaeBr1ii"}},{"cell_type":"markdown","source":["### Library Package"],"metadata":{"id":"nQmo-daBsSkK"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","from sklearn import datasets as dat\n","from sklearn import tree\n","from sklearn import metrics as met\n","from sklearn import model_selection as mod\n","from sklearn import linear_model as lin\n","from sklearn import preprocessing as pre\n","from sklearn import pipeline as pip # sklearn pipeline\n","from sklearn import svm"],"metadata":{"id":"3i7_yQSHsXIW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Algorithms"],"metadata":{"id":"TFR47peRsoKm"}},{"cell_type":"code","source":["#SVMs with Linear\n","\n","pipe = pip.Pipeline([\n","    (\"scaler\", pre.StandardScaler()),\n","    (\"clf\", svm.LinearSVC(loss=\"hinge\", C=1))\n","])\n","\n","mod.cross_val_score(pipe, X, y, cv=3).mean()"],"metadata":{"id":"Kh1ki97vsqwx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SVMs with Polynomial Features\n","\n","pipe = pip.Pipeline([\n","    (\"scaler\", pre.StandardScaler()),\n","    (\"svm\", svm.SVC(kernel=\"poly\", degree=3, coef0=1, C=1, random_state=42, max_iter=5000))\n","])\n","\n","mod.cross_val_score(pipe, X, y, cv=3, scoring=\"accuracy\").mean()"],"metadata":{"id":"Ic8CKjU9s518"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SVMs with Gaussian RBF kernel\n","\n","pipe = pip.Pipeline([\n","    (\"scaler\", pre.StandardScaler()),\n","    (\"svm\", svm.SVC(kernel=\"rbf\", gamma=1, C=1, random_state=42, max_iter=5000))\n","])\n","\n","mod.cross_val_score(pipe, X, y, cv=3, scoring=\"accuracy\").mean()"],"metadata":{"id":"InsTOkATtNfs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Missing Value Imputation"],"metadata":{"id":"uKFt37_6zBfC"}},{"cell_type":"markdown","source":["### Library Package"],"metadata":{"id":"g2YR3U-JzZTv"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","from sklearn import datasets as dat\n","from sklearn import tree\n","from sklearn import metrics as met\n","from sklearn import model_selection as mod\n","from sklearn import linear_model as lin\n","from sklearn import preprocessing as pre\n","from sklearn import pipeline as pip # sklearn pipeline\n","from sklearn import svm\n","from sklearn import impute as imp\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn import compose as com"],"metadata":{"id":"ygOyMKN6zXwP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Algorithms"],"metadata":{"id":"LegKz1vFzhXE"}},{"cell_type":"code","source":["pd.DataFrame(X).isnull().sum()"],"metadata":{"id":"8F538yEazoPZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_values, y_values = [], []"],"metadata":{"id":"ARw1bHXY0I52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Simple Imputer\n","for s in [\"mean\", \"median\"]:\n","  pipe = pip.Pipeline([\n","      (\"scaler\", pre.StandardScaler()),\n","      (\"imp\", imp.SimpleImputer(strategy=s)),\n","      (\"sgd_reg\", lin.SGDRegressor(random_state=42))\n","  ])\n","\n","  score = mod.cross_val_score(pipe, X, y, scoring=\"neg_root_mean_squared_error\").mean() * -1\n","\n","  y_values.append(score)\n","  x_values.append(\"SimpleImp_\" + s)"],"metadata":{"id":"nz79Ivipzwb7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# KNN Imputer\n","\n","for w in [\"uniform\", \"distance\"]:\n","  for k in [5, 22]:\n","    pipe = pip.Pipeline([\n","        (\"scaler\", pre.StandardScaler()),\n","        (\"imp\", imp.KNNImputer(n_neighbors=k, weights=w)),\n","        (\"sgd_reg\", lin.SGDRegressor(random_state=42))\n","    ])\n","\n","    score = mod.cross_val_score(pipe, X, y, scoring=\"neg_root_mean_squared_error\").mean() * -1\n","\n","    y_values.append(score)\n","    x_values.append(\"KNNImp_\" + w + \"_\" + str(k))"],"metadata":{"id":"PWsW6XE5zwZR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for est in [lin.SGDRegressor(random_state=42),\n","            lin.BayesianRidge(),\n","            tree.DecisionTreeRegressor(random_state=42)]:\n","  pipe = pip.Pipeline([\n","      (\"scaler\", pre.StandardScaler()),\n","      (\"imp\", imp.IterativeImputer(estimator=est, max_iter=5)),\n","      (\"sgd_reg\", lin.SGDRegressor(random_state=42))\n","  ])\n","\n","  score = mod.cross_val_score(pipe, X, y, scoring=\"neg_root_mean_squared_error\").mean() * -1\n","\n","  y_values.append(score)\n","  x_values.append(\"IterativeImp_\" + est.__class__.__name__)\n","\n","\n","\n","plt.bar(x_values, y_values)\n","plt.ylim(0.7, 0.9)\n","plt.xticks(rotation=80)\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"nBtcavBnzwWT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe_num = pip.Pipeline([\n","    (\"scaler\", pre.StandardScaler()),\n","    (\"imp\", imp.SimpleImputer(strategy=\"mean\"))\n","])\n","\n","pipe_num2 = pip.Pipeline([\n","    (\"scaler\", pre.StandardScaler()),\n","    (\"imp\", imp.KNNImputer())\n","])\n","\n","pipe_cat = pip.Pipeline([\n","    (\"imp\", imp.SimpleImputer(strategy=\"most_frequent\")),\n","    (\"one_hot\", pre.OneHotEncoder(handle_unknown=\"ignore\"))\n","])\n","\n","#np.set_printoptions(suppress=True)\n","#pipe_num.fit_transform(data.select_dtypes(exclude=\"object\"))\n","\n","ct = com.ColumnTransformer([\n","    (\"num\", pipe_num, [\"age\"]),\n","    (\"num2\", pipe_num, [\"salary\"]),\n","    (\"cat\", pipe_cat, [\"city\"]),\n","])\n","\n","ct.fit_transform(data)"],"metadata":{"id":"uDtYeA-O05H9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ct.transform(data_test)"],"metadata":{"id":"cMsr3D9Z1Av7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe_all = pip.Pipeline([\n","    (\"ct\", ct),\n","    (\"sgd\", lin.SGDClassifier())\n","])\n","\n","pipe_all.fit(data, [0, 1, 1, 0])"],"metadata":{"id":"2NBjGl4I1BQg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#second WAY \n","\n","pipe_cat = pip.Pipeline([\n","    (\"encoding\", pre.OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n","    (\"scaler\", pre.StandardScaler())\n","])\n","\n","ct = com.ColumnTransformer([\n","    (\"cat\", pipe_cat, [\"Regional indicator\"]), # 10\n","    (\"num\", pre.StandardScaler(), X_train.select_dtypes(exclude=\"object\").columns) # 17\n","])\n","\n","ct.fit_transform(X_train).shape"],"metadata":{"id":"DVKHZnPH36sH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"5j1fvHu34nZN"}},{"cell_type":"markdown","source":["## Dimensionality Reduction"],"metadata":{"id":"o-UHoebk4pGf"}},{"cell_type":"markdown","source":["*   **Linear Projection**\n","    - Principal Component Analysis (PCA)\n","        * Feature scaling is required\n","        * PCA finds a low-dimensional representation of the data\n","        * It focuses the correlation among the features. \n","        * Its combining the highly correlated features and represent this data with a smaller number of linearly uncorrelated features.\n","        * PCA finds the directions of maximum variance in the original high-dimensional data and projecting them onto a smaller dimensional space.\n","\n","    - Singular Value Decomposition (SVD)\n","\n","*   **Manifold Learning (Nonlinear Dimensionality Reduction**\n","    - T-distributed Stochastic Neighbor Embedding (t-SNE)\n","        * t-SNE is a nonlinear dimensionality reduction technique for visualizing high-dimensional data.\n","        * t-SNE minimizes the **Kullback–Leibler divergence** between the two probability distributions.\n","\n"],"metadata":{"id":"EfmXhLwN49cp"}},{"cell_type":"markdown","source":["**NOTE :** Normal PCA, incremental PCA linearly project the original data onto a lower dimensional space, but there is also a nonlinear form of PCA known as kernel PCA, which runs a similarity function over pairs of original data points in order to perform nonlinear dimensionality reduction."],"metadata":{"id":"kpTFZrKz8oCn"}},{"cell_type":"markdown","source":["For the kernel PCA algorithm, we need to set:\n","*   the number of components\n","*   the type of kernel\n","*   the kernel coefficient, which is known as the gamma."],"metadata":{"id":"EG7C5QZ_82LV"}},{"cell_type":"markdown","source":["A practical tip - t-SNE:\n","*   First apply PCA to get around 50 features from N features (N >> 50)\n","*   Then, apply t-SNE to get 2-3 features from 50 features"],"metadata":{"id":"fVfsbveC_Lk_"}},{"cell_type":"markdown","source":["### Library Package"],"metadata":{"id":"WnijIja0_5yb"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","\n","from matplotlib import pyplot as plt\n","\n","from sklearn import datasets as dat\n","from sklearn import ensemble as ens\n","from sklearn import pipeline as pip\n","from sklearn import preprocessing as pre\n","from sklearn import decomposition as dec\n","from sklearn import manifold as man\n","from sklearn import model_selection as mod\n","from sklearn import linear_model as lin"],"metadata":{"id":"w7hH_Sgz_-Zk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Algorithms"],"metadata":{"id":"v2ororVe__SQ"}},{"cell_type":"code","source":["data = dat.fetch_openml(\"mnist_784\")"],"metadata":{"id":"ZxBXtrP1ACkm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = data.data.values\n","y = data.target.values"],"metadata":{"id":"mIsR17K3BzMW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.scatterplot(x=X[:, 250], y=X[:, 366], hue=y)"],"metadata":{"id":"zADjQsBeB4QW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["est = ens.RandomForestClassifier(n_estimators=10)\n","est.fit(X, y)"],"metadata":{"id":"h0BY200UB4NU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.set_printoptions(suppress=True)\n","est.feature_importances_.argsort()[::-1][:2]"],"metadata":{"id":"wOfYHaXEB4Jx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.scatterplot(x=X[:, 569], y=X[:, 350], hue=y)"],"metadata":{"id":"LGeuJyWWB-S2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe = pip.Pipeline([\n","    (\"scaler\", pre.StandardScaler()),\n","    (\"pca\", dec.PCA(n_components=2)) # unsupervised learning method\n","])\n","\n","X_new = pipe.fit_transform(X) # X.shape -> (70000, 784) ==> X_new.shape -> (70000, 2)\n","X_new.shape"],"metadata":{"id":"t4DMV_jhCOBN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe.named_steps[\"pca\"].components_.shape"],"metadata":{"id":"qeQXaBvTCVUu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe.named_steps[\"pca\"].explained_variance_ratio_"],"metadata":{"id":"xGgVT0cwCWC_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe.named_steps[\"pca\"].explained_variance_ratio_.sum()"],"metadata":{"id":"Xr4GN1cRCV2V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.scatterplot(x=X_new[:, 0], y=X_new[:, 1], hue=y)"],"metadata":{"id":"RTw0OZJJCh_y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe = pip.Pipeline([\n","    (\"scaler\", pre.StandardScaler()),\n","    (\"pca\", dec.PCA(random_state=42))\n","])\n","\n","pipe.fit(X)"],"metadata":{"id":"k58IUjYtDA7b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ratios = pipe.named_steps[\"pca\"].explained_variance_ratio_\n","\n","x_values, y_values = [], []\n","\n","for i in range(1, 784):\n","  var = ratios[:i].sum()\n","  y_values.append(var)\n","  x_values.append(i)\n","\n","plt.bar(x_values, y_values)\n","plt.show()"],"metadata":{"id":"PsPQZLb9DC-n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ratios[:250].sum()"],"metadata":{"id":"3vnwCobPDSSb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe = pip.Pipeline([\n","    (\"scaler\", pre.StandardScaler()),\n","    (\"pca\", dec.PCA(n_components=300, random_state=42)),\n","    #(\"sgd\", lin.SGD...)\n","])"],"metadata":{"id":"OURKFchpDTij"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe = pip.Pipeline([\n","    (\"scaler\", pre.StandardScaler()),\n","    (\"pca\", dec.PCA(n_components=100, random_state=42)),\n","    (\"tsne\", man.TSNE(n_components=2, random_state=42)) # unsupervised learning method\n","])\n","\n","X_tsne = pipe.fit_transform(X[:5000])"],"metadata":{"id":"6fN9Uww0DXUk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_tsne.shape # 5000, 2"],"metadata":{"id":"wNOf1Gv0DcUu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.scatterplot(x=X_tsne[:, 0], y=X_tsne[:, 1], hue=y[:5000])"],"metadata":{"id":"uuFe1KPSDdKH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe.named_steps[\"pca\"].components_.shape"],"metadata":{"id":"vhVoAeopELof"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(10):\n","  sns.heatmap(pipe.named_steps[\"pca\"].components_[i].reshape(28, 28))\n","  plt.show()"],"metadata":{"id":"yLyr0OPxEQgx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Machine Learning - Unsupervised Learning By OV"],"metadata":{"id":"zGPyh2H-TvAh"}},{"cell_type":"markdown","source":["Dimensionality reduction \n","*   Matrix factorization: PCA, SVD\n","*   Manifold learning: MDS, t-SNE, UMAP\n","\n"],"metadata":{"id":"Q9PItwUFT-Ic"}},{"cell_type":"markdown","source":["Clustering\n","* Hierarchical\n","* K-Means\n","* DBSCAN\n","* GMM"],"metadata":{"id":"qRsFllgbcU62"}},{"cell_type":"markdown","source":["* Hierarchical clustering doesn’t require defining number of\n","clusters in advance, instead builds dendrogram\n","* It’s intuitive since we tend to group or split items based\n","on their similarities\n","* Time complexity is not ideal since it requires pairwise\n","operation O(n2)\n","* Linkage method has an influence on outcomes"],"metadata":{"id":"LNwvkKh3dMV9"}},{"cell_type":"markdown","source":["Internal Measures: Choosing K by using the **average SILHOUETTE WIDTH**"],"metadata":{"id":"oVBoHxWAewpm"}},{"cell_type":"markdown","source":["Network properties\n","* Degree: # of connections\n","with other nodes\n","* Strength: sum of weights\n","attached to a node\n","* Density: fraction between #\n","of existing ties and"],"metadata":{"id":"_XHxoaAUfy3y"}},{"cell_type":"markdown","source":["## Algorithms"],"metadata":{"id":"1LRMwMZ6gw9-"}},{"cell_type":"markdown","source":["### Library Package"],"metadata":{"id":"6DFZ41ekg1ua"}},{"cell_type":"code","source":["# Let's import some of the necessary libraries\n","import gzip\n","import json\n","import glob\n","import numpy as np\n","import networkx as nx\n","\n","import matplotlib as mpl\n","from matplotlib import pyplot as plt\n","\n","import pandas as pd\n","\n","\n","DATA_PATH = '/content/'\n","#DATA_PATH = '/content/'\n","\n","# https://pypi.org/project/watermark/\n","!pip install watermark\n","!pip install packagename==0.0.1\n","\n","import watermark\n","%load_ext watermark\n","%watermark -n -v -m -g -iv"],"metadata":{"id":"mtp6ZFwyg7gR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Algorithms"],"metadata":{"id":"yDrU6_BIg9X4"}},{"cell_type":"code","source":["ivaaData = {\n","    \"Haci S.\": [[\"Evrim K.\", \"Erdal K.\", \"Atif B.\"], \"AkcanSA\"],\n","    \"Enes G.\": [[\"Onur A.\", \"Cumali K.\", \"Nurullah B.\"], \"EnerjiSA\"],\n","    \"Cemil C.\": [[\"Ozge A.\", \"Volkan Z.\", \"Cumali K.\"], \"EnerjiSA\"],\n","    \"Erdal K.\": [[\"Ensari Y.\", \"Haci S.\", \"Atif B.\"], \"TemSA\"],\n","    \"Tugce A.\": [[\"Beste B.\", \"Erhan T.\", \"Selda O.\"], \"AgeSA\"],\n","    \"Atif B.\": [[\"Evrim K.\", \"Erdal K.\", \"Haci S.\"], \"EnerjiSA-U\"],\n","    \"Beste B.\": [[\"Tugce A.\", \"Nurullah B.\", \"Erhan T.\"], \"BriSA\"],\n","    \"Asli C.\": [[\"Irem E.\", \"Cumali K.\", \"Onur A.\"], \"EnerjiSA\"],\n","    \"Volkan Z.\": [[\"Cemil C.\", \"Ozge A.\", \"Cumali K.\"], \"EnerjiSA\"],\n","    \"Irem E.\": [[\"Asli C.\", \"Onur A.\", \"Cumali K.\"], \"EnerjiSA\"],\n","    \"Ozge A.\": [[\"Cemil C.\", \"Volkan Z.\", \"Enes G.\"], \"EnerjiSA\"],\n","    \"Evrim K.\": [[\"Haci S.\", \"Atif B.\", \"Ensari Y.\"], \"AkcanSA\"],\n","    \"Cumali K.\": [[\"Onur A.\", \"Irem E.\", \"Asli C.\"], \"CimSA\"],\n","    \"Onur A.\": [[\"Cumali K.\", \"Asli C.\", \"Irem E.\"], \"EnerjiSA\"],\n","    \"Selda O.\": [[\"Erhan T.\", \"Tugce A.\", \"Beste B.\"], \"EnerjiSA\"],\n","    \"Ensari Y.\": [[], \"EnerjiSA\"],\n","    \"Nurullah B.\": [[], \"KordSA\"],\n","    \"Erhan T.\": [[], \"EnerjiSA\"]\n","}"],"metadata":{"id":"8HvdAKPxhB-i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(ivaaData))\n","uniqueNames = set()\n","for k,v in ivaaData.items():\n","  uniqueNames.add(k)\n","  uniqueNames |= set(v[0])\n","print(len(uniqueNames))"],"metadata":{"id":"e0O2usCHhq42"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ivaaNet = nx.DiGraph()\n","\n","for nodeA,neig in ivaaData.items():\n","  for nodeB in neig[0]:\n","    #print(nodeA, nodeB)\n","    ivaaNet.add_edge(nodeA, nodeB)\n","\n","  ivaaNet.nodes[nodeA]['company'] = neig[1]\n","\n","nx.info(ivaaNet)"],"metadata":{"id":"p476eSzKh1Rk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dict(ivaaNet.in_degree())"],"metadata":{"id":"NK88VyhOh1uo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["betweennessC = nx.betweenness_centrality(ivaaNet)\n","for n in sorted(betweennessC, key=betweennessC.get, reverse=True):\n","    print(n, betweennessC[n])\n"],"metadata":{"id":"eQHi9XoKh362"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#pos = nx.spring_layout(ivaaNet)\n","#nx.draw_networkx(ivaaNet, pos=pos)\n","\n","nx.write_gexf(ivaaNet, 'ivaaNet.gexf')"],"metadata":{"id":"R41yyq-ah6-i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aGtWGyWth96c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Building Methods"],"metadata":{"id":"ZETfwoHkehJl"}},{"cell_type":"code","source":["def reading_data(path, sep ):\n","  df_data = pd.read_csv(path,sep=sep)\n","  df_data.head()"],"metadata":{"id":"nxXYiy6belW_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def creating_New_feature(feature_Data):\n","  new_fea = "],"metadata":{"id":"9igbC90PfaK8"},"execution_count":null,"outputs":[]}]}